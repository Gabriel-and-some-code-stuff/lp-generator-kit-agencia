import pandas as pd
import os

# Configura√ß√µes
PLANILHA_INPUT = "clientes.csv"  # Nome do arquivo CSV exportado da planilha
PLANILHA_OUTPUT = "clientes_processados.csv" # Onde vamos salvar os resultados

def ler_planilha():
    """
    L√™ o arquivo CSV exportado do Google Sheets.
    Assume que:
    - Coluna A (√≠ndice 0) √© o Nome do Cliente
    - Coluna C (√≠ndice 2) √© a URL do Site
    """
    if not os.path.exists(PLANILHA_INPUT):
        print(f"‚ùå Erro: Arquivo '{PLANILHA_INPUT}' n√£o encontrado na raiz.")
        print("   -> Exporte sua planilha do Google como CSV e salve aqui.")
        return None

    try:
        # L√™ o CSV. O header=0 significa que a primeira linha √© o cabe√ßalho.
        # Ajuste 'usecols' se souber os nomes exatos das colunas, ou use √≠ndices.
        # Aqui, vamos ler tudo e filtrar pelo √≠ndice para garantir.
        df = pd.read_csv(PLANILHA_INPUT)
        
        print(f"‚úÖ Planilha carregada com sucesso! Encontradas {len(df)} linhas.")
        return df
    
    except Exception as e:
        print(f"‚ùå Erro ao ler CSV: {e}")
        return None

def processar_clientes(df):
    """Itera sobre os clientes e extrai as informa√ß√µes b√°sicas."""
    
    # Lista para guardar resultados (ser√° √∫til na fase de escrita)
    resultados = []

    for index, row in df.iterrows():
        # Acessa por posi√ß√£o (iloc) ou nome da coluna se o CSV tiver cabe√ßalho limpo
        # Ajuste os √≠ndices conforme sua planilha real:
        # Coluna A -> √≠ndice 0 (Nome)
        # Coluna C -> √≠ndice 2 (URL)
        
        try:
            nome_cliente = str(row.iloc[0]).strip()
            url_site = str(row.iloc[2]).strip()
            
            # Valida√ß√£o b√°sica
            if pd.isna(url_site) or url_site == 'nan' or not url_site.startswith('http'):
                print(f"‚ö†Ô∏è  Linha {index + 2}: URL inv√°lida ou vazia para {nome_cliente}. Pulando.")
                continue

            print(f"üöÄ Processando Cliente {index + 1}: {nome_cliente}")
            print(f"   üîó URL Alvo: {url_site}")
            
            # AQUI ENTRAR√Å A FASE 2 (SCRAPING) E 3 (IA)
            # Por enquanto, apenas simulamos
            lp_gerada = "https://lp-teste.vercel.app" # Placeholder
            
            # Adiciona ao resultado para salvar depois
            resultados.append({
                "Nome": nome_cliente,
                "URL Original": url_site,
                "LP Gerada": lp_gerada
            })
            
        except Exception as e:
            print(f"‚ùå Erro na linha {index + 2}: {e}")

    return pd.DataFrame(resultados)

if __name__ == "__main__":
    print("ü§ñ Iniciando Agente de Landing Pages...")
    
    df_clientes = ler_planilha()
    
    if df_clientes is not None:
        df_resultados = processar_clientes(df_clientes)
        
        # Salva o output (simulando a escrita na Coluna E)
        if not df_resultados.empty:
            df_resultados.to_csv(PLANILHA_OUTPUT, index=False)
            print(f"\nüíæ Resultados salvos em '{PLANILHA_OUTPUT}'")
        else:
            print("\n‚ö†Ô∏è Nenhum cliente processado com sucesso.")